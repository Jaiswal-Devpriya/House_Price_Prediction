{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14a412-db58-4d01-89e0-2ce27dfc217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the entire file to understand what the data means\n",
    "with open('data_description.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7d7aa-e81d-42cd-a14a-9d6dd5b17160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing the sample data to understand the metadata and its value\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bda2e-c572-4931-af69-ea17aa35c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9f20c-1f4e-433b-b81f-fa71be92534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To know number of rows and column\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a579db-2457-4ddf-ac83-fee824a796e5",
   "metadata": {},
   "source": [
    "The train_data has 1460 rows and 81 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cc350-6740-4ad2-8925-96f713bd763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5caeea-1a39-416d-a921-b4ba37b47b83",
   "metadata": {},
   "source": [
    "The datatypes for the columns are as follows:\n",
    "float64(3): 3 columns containing decimal numbers\n",
    "\n",
    "int64(35): 35 columns containing whole numbers\n",
    "\n",
    "object(43): 43 columns containing text/categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d2752-d30e-4a43-bf52-f4250a1eea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d06714-4417-407f-b179-e2601ef426d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which column has missing values, because above commmand does not give complete idea of all the columns\n",
    "missing_columns = train_data.isnull().sum()\n",
    "missing_column_name = missing_columns[missing_columns > 0]\n",
    "\n",
    "\n",
    "print(f\"Column with missing values: {missing_column_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572893a-d17c-4a69-876f-899e01c91b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = train_data.columns[train_data.isnull().any()]\n",
    "\n",
    "for col in missing_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Data type: {train_data[col].dtype}\")\n",
    "    print(f\"Unique values sample: {train_data[col].unique()[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d2f33-187c-4715-a12e-caebe37bfc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill \"None\" categorical features\n",
    "none_cols = [\n",
    "    \"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "    \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\",\n",
    "    \"GarageType\", \"GarageFinish\", \"GarageQual\",\n",
    "    \"GarageCond\", \"PoolQC\", \"Fence\", \"MiscFeature\",\n",
    "    \"MasVnrType\"\n",
    "]\n",
    "\n",
    "for col in none_cols:\n",
    "    if col in train_data.columns:\n",
    "        train_data[col] = train_data[col].fillna(\"None\")\n",
    "\n",
    "\n",
    "# Fill zero numeric features\n",
    "zero_cols = [\n",
    "    \"GarageYrBlt\", \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\",\n",
    "    \"GarageArea\", \"GarageCars\"\n",
    "]\n",
    "\n",
    "for col in zero_cols:\n",
    "    if col in train_data.columns:\n",
    "        train_data[col] = train_data[col].fillna(0)\n",
    "\n",
    "\n",
    "# LotFrontage (important improvement)\n",
    "train_data[\"LotFrontage\"] = train_data.groupby(\"Neighborhood\")[\"LotFrontage\"]\\\n",
    "                                      .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "train_data[\"LotFrontage\"] = train_data[\"LotFrontage\"].fillna(train_data[\"LotFrontage\"].median())\n",
    "\n",
    "\n",
    "# Electrical (mode)\n",
    "if \"Electrical\" in train_data.columns:\n",
    "    train_data[\"Electrical\"] = train_data[\"Electrical\"].fillna(\n",
    "        train_data[\"Electrical\"].mode()[0]\n",
    "    )\n",
    "\n",
    "\n",
    "# Final safety fill (just in case)\n",
    "train_data = train_data.fillna(train_data.median(numeric_only=True))\n",
    "\n",
    "for col in train_data.select_dtypes(include=\"object\"):\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].mode()[0])\n",
    "\n",
    "\n",
    "# Check remaining\n",
    "print(\"Remaining missing values:\", train_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8cc17-a1fc-483a-8a2c-e2d68edf23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Square Footage\n",
    "train_data[\"TotalSF\"] = (\n",
    "    train_data[\"TotalBsmtSF\"] +\n",
    "    train_data[\"1stFlrSF\"] +\n",
    "    train_data[\"2ndFlrSF\"]\n",
    ")\n",
    "\n",
    "# Total Bathrooms (weighted)\n",
    "train_data[\"TotalBath\"] = (\n",
    "    train_data[\"FullBath\"] +\n",
    "    0.5 * train_data[\"HalfBath\"] +\n",
    "    train_data[\"BsmtFullBath\"] +\n",
    "    0.5 * train_data[\"BsmtHalfBath\"]\n",
    ")\n",
    "\n",
    "# Total Porch Area\n",
    "train_data[\"TotalPorchSF\"] = (\n",
    "    train_data[\"OpenPorchSF\"] +\n",
    "    train_data[\"EnclosedPorch\"] +\n",
    "    train_data[\"3SsnPorch\"] +\n",
    "    train_data[\"ScreenPorch\"] +\n",
    "    train_data[\"WoodDeckSF\"]\n",
    ")\n",
    "\n",
    "# House Age\n",
    "train_data[\"HouseAge\"] = train_data[\"YrSold\"] - train_data[\"YearBuilt\"]\n",
    "\n",
    "# Remodel Age\n",
    "train_data[\"RemodelAge\"] = train_data[\"YrSold\"] - train_data[\"YearRemodAdd\"]\n",
    "\n",
    "# Was Remodeled?\n",
    "train_data[\"Remodeled\"] = (\n",
    "    train_data[\"YearRemodAdd\"] != train_data[\"YearBuilt\"]\n",
    ").astype(int)\n",
    "\n",
    "# Has Garage?\n",
    "train_data[\"HasGarage\"] = (train_data[\"GarageArea\"] > 0).astype(int)\n",
    "\n",
    "# Has Basement?\n",
    "train_data[\"HasBasement\"] = (train_data[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "# Has Pool?\n",
    "train_data[\"HasPool\"] = (train_data[\"PoolArea\"] > 0).astype(int)\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc920e7d-be86-47ba-b710-340631930626",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"OverallQual_TotalSF\"] = (\n",
    "    train_data[\"OverallQual\"] * train_data[\"TotalSF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bc5b6-6219-43cd-8b84-b2d79ea041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "import numpy as np\n",
    "\n",
    "# Separate target\n",
    "y = np.log1p(train_data[\"SalePrice\"])\n",
    "\n",
    "# Drop target + Id\n",
    "X = train_data.drop([\"SalePrice\", \"Id\"], axis=1)\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_feats = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# Compute skewness\n",
    "skewness = X[numeric_feats].apply(lambda x: skew(x))\n",
    "skewed_features = skewness[skewness > 0.75].index\n",
    "\n",
    "print(\"Number of skewed features:\", len(skewed_features))\n",
    "\n",
    "# Apply log1p transformation\n",
    "X[skewed_features] = np.log1p(X[skewed_features])\n",
    "\n",
    "print(\"Skewness correction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6869a-39be-47e5-a97f-474034e6d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "print(\"Final feature count:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae5bb6-d2b0-4992-b28a-772bcca249a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse = np.sqrt(-cross_val_score(\n",
    "        model, X, y,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=cv\n",
    "    ))\n",
    "    return rmse.mean()\n",
    "\n",
    "# Ridge\n",
    "ridge = Ridge(alpha=10)\n",
    "print(\"Ridge RMSE:\", rmse_cv(ridge))\n",
    "\n",
    "# Lasso\n",
    "lasso = Lasso(alpha=0.0005, random_state=42)\n",
    "print(\"Lasso RMSE:\", rmse_cv(lasso))\n",
    "\n",
    "# ElasticNet\n",
    "elastic = ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=42)\n",
    "print(\"ElasticNet RMSE:\", rmse_cv(elastic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62705306-8535-456f-8c1f-33f8415d2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93622296-44bc-41b5-95d8-aad1430e8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rmse_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    preds = lgb_model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "print(\"LightGBM RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41de78a-b5a3-4fa1-b07e-742f2c98e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=20,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rmse_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    "    )\n",
    "\n",
    "    preds = lgb_model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "print(\"Tuned LightGBM RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877b44d-ce2a-4ce9-9172-84dbb4112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "alphas = [0.0001, 0.0003, 0.0005, 0.0007, 0.001, 0.002]\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, random_state=42)\n",
    "    score = rmse_cv(lasso)\n",
    "    print(f\"alpha={alpha} -> RMSE: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83deb013-b7a9-4c88-99b5-5d26e30b95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Final model\n",
    "final_model = Lasso(alpha=0.0005, random_state=42)\n",
    "\n",
    "# Fit on full training data\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print(\"Final model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0eba31-ebca-413f-89aa-ce1b69d5e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Helper: recreate engineered features on test set ----------\n",
    "def add_engineered_features(df):\n",
    "    # Make sure required base columns exist; if not, code will raise informative KeyError\n",
    "    df[\"TotalSF\"] = df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    df[\"TotalBath\"] = df[\"FullBath\"] + 0.5 * df[\"HalfBath\"] + df[\"BsmtFullBath\"] + 0.5 * df[\"BsmtHalfBath\"]\n",
    "    df[\"TotalPorchSF\"] = (df[\"OpenPorchSF\"] + df[\"EnclosedPorch\"] + df[\"3SsnPorch\"] +\n",
    "                          df[\"ScreenPorch\"] + df[\"WoodDeckSF\"])\n",
    "    df[\"HouseAge\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "    df[\"RemodelAge\"] = df[\"YrSold\"] - df[\"YearRemodAdd\"]\n",
    "    df[\"Remodeled\"] = (df[\"YearRemodAdd\"] != df[\"YearBuilt\"]).astype(int)\n",
    "    df[\"HasGarage\"] = (df[\"GarageArea\"] > 0).astype(int)\n",
    "    df[\"HasBasement\"] = (df[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "    df[\"HasPool\"] = (df[\"PoolArea\"] > 0).astype(int)\n",
    "    # interaction used in training\n",
    "    df[\"OverallQual_TotalSF\"] = df[\"OverallQual\"] * df[\"TotalSF\"]\n",
    "    return df\n",
    "\n",
    "# ---------- 1) Ensure test_data has basic imputations consistent with train ----------\n",
    "# (If you used more sophisticated imputation in train, re-run the same steps here.)\n",
    "# Example minimal re-imputation mirroring earlier steps:\n",
    "# Fill \"None\" categorical features used earlier:\n",
    "none_cols = [\n",
    "    \"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "    \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\",\n",
    "    \"GarageType\", \"GarageFinish\", \"GarageQual\",\n",
    "    \"GarageCond\", \"PoolQC\", \"Fence\", \"MiscFeature\",\n",
    "    \"MasVnrType\"\n",
    "]\n",
    "for col in none_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].fillna(\"None\")\n",
    "\n",
    "# Zero numeric features used earlier\n",
    "zero_cols = [\n",
    "    \"GarageYrBlt\", \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\",\n",
    "    \"GarageArea\", \"GarageCars\"\n",
    "]\n",
    "for col in zero_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].fillna(0)\n",
    "\n",
    "# LotFrontage by neighborhood: use train medians if you have them else groupby test\n",
    "if \"LotFrontage\" in test_data.columns:\n",
    "    if \"Neighborhood\" in train_data.columns:\n",
    "        # use medians computed from train_data (safer)\n",
    "        lot_med_by_nb = train_data.groupby(\"Neighborhood\")[\"LotFrontage\"].median()\n",
    "        test_data[\"LotFrontage\"] = test_data.apply(\n",
    "            lambda r: lot_med_by_nb[r[\"Neighborhood\"]] if pd.isna(r[\"LotFrontage\"]) else r[\"LotFrontage\"],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        # fallback: fill with global median of test\n",
    "        test_data[\"LotFrontage\"] = test_data[\"LotFrontage\"].fillna(test_data[\"LotFrontage\"].median())\n",
    "\n",
    "# Electrical mode\n",
    "if \"Electrical\" in test_data.columns:\n",
    "    test_data[\"Electrical\"] = test_data[\"Electrical\"].fillna(train_data[\"Electrical\"].mode()[0])\n",
    "\n",
    "# Final safety numeric median fill and categorical mode fill (mirrors earlier)\n",
    "test_data = test_data.fillna(test_data.median(numeric_only=True))\n",
    "for col in test_data.select_dtypes(include=\"object\"):\n",
    "    test_data[col] = test_data[col].fillna(train_data[col].mode()[0] if col in train_data.columns else test_data[col].mode()[0])\n",
    "\n",
    "# ---------- 2) Add engineered features to test ----------\n",
    "test_data = add_engineered_features(test_data)\n",
    "\n",
    "# ---------- 3) Skew correction: use the same skewed_features list you computed for X ----------\n",
    "# If you don't have 'skewed_features' variable available, recompute from training X numeric cols.\n",
    "try:\n",
    "    sf = skewed_features  # variable from your earlier steps\n",
    "except NameError:\n",
    "    # Compute from training feature matrix X (before one-hot) if available\n",
    "    # If X was already one-hot, we recompute skew candidates from train_data numeric columns\n",
    "    numeric_feats = train_data.select_dtypes(include=[np.number]).columns\n",
    "    from scipy.stats import skew\n",
    "    sk = train_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_features = sk[sk > 0.75].index.tolist()\n",
    "    sf = skewed_features\n",
    "\n",
    "# Only transform columns that actually exist in test_data\n",
    "sf_existing = [c for c in sf if c in test_data.columns]\n",
    "test_data.loc[:, sf_existing] = np.log1p(test_data.loc[:, sf_existing])\n",
    "\n",
    "# ---------- 4) One-hot encode test and align with training X ----------\n",
    "X_test = test_data.drop(\"Id\", axis=1).copy()\n",
    "\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Align columns: reindex to training feature set X.columns (fill missing with 0)\n",
    "# Ensure X (train feature matrix) variable exists\n",
    "if 'X' not in globals():\n",
    "    raise RuntimeError(\"Training feature matrix `X` not found. Make sure X (processed train features) exists before aligning test.\")\n",
    "\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "print(\"Test data columns aligned to training columns. Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70a9ed-c7d7-4d6c-9132-9b172f3aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "final_model = Lasso(alpha=0.0005, random_state=42, max_iter=20000)\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cbc35-843e-4f1c-97c9-fc5159f2fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_preds = final_model.predict(X_test)\n",
    "final_preds = np.expm1(log_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27e7ba-31c9-4f94-b0c8-5a7cd4be3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_data[\"Id\"],\n",
    "    \"SalePrice\": final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9a9ad-a577-4f83-b457-ad18c65e7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission.shape)\n",
    "print(submission.isnull().sum())\n",
    "print(submission[\"SalePrice\"].min(), submission[\"SalePrice\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa96ae-f8dc-460d-8345-5112ee405c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
